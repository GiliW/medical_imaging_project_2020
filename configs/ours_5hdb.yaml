dataset: 5hdb
lr: 1e-4                        # Learning rate
step_size: 200                  # Period of learning rate decay
lr_disc: 1e-4                   # Discriminator learning rate
step_size_disc: 95              # Period of discriminator learning rate decay
batch_size: 256                 # Mini-batch size
num_workers: 4                  # Number of cpu workers in pytorch dataloader
num_epochs: 300                 # Number of training epochs
discriminator_idle_freq: 4      # Number of batches in which the discriminator (critic) is not updated (default 5)
generator_idle_freq: 1          # Number of batches in which the generator is not updated (default 1)
weight_decay: 1e-5              # L2 penalty
last_activation: fc             # last activation layer of the generator. fc for 5hdb and tanh for MNIST.

# Architecture
z_dim: 32                       # Latent variable dimension
architecture: cnn               # Which architecture to use (cnn or fc). cnn for DCGAN.
use_wasserstein: true

# Visualization and debug
batches_to_viz: 5               # Number of batches to perform visualization
viz_num_per_batch: 10           # Number of images to visualize in a batch
viz_epoch_rate: 5               # Epoch frequency to save visualization (i.e. every 5 epochs)
fast_dev_run: false             # runs 1 batch of train, test and val

hydra:
  run:
    # Output directory
    dir: ../output/ours_5hdb_${now:%Y%m%d_%H%M%S}
